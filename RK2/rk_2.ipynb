{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Зудин Алексей Максимович, ИУ5-63Б <br/>Вариант №10: метод №1 -Дерево решений; <br/>метод №2 - Случайный лес."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для рубежного контроля №2 согласно варианту взят [следующий датасет.](https://www.kaggle.com/jessemostipak/hotel-booking-demand)\n",
    "Будем решать задачу бинарной классификации: будет ли отменено бронирование данной комнаты в отеле (**is_canceled** - целевой признак) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-1-30a92b56e7eb>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodel_selection\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mtrain_test_split\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmetrics\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mbalanced_accuracy_score\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mplot_roc_curve\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mconfusion_matrix\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0mseaborn\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0msns\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      9\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mmatplotlib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpyplot\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtree\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mDecisionTreeClassifier\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import MissingIndicator\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, plot_roc_curve, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отбираем 5000 строк из всего датасета\n",
    "data = pd.read_csv('data/hotel_bookings.csv', nrows=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оцениваем баланс классов целевого признака\n",
    "data['is_canceled'].value_counts()/data['is_canceled'].shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверяем процент пропусков в данных для всех колонок\n",
    "(data.isnull().sum()/data.shape[0]*100).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Строим гистограмму распределения для импутируемого признака\n",
    "g = sns.kdeplot(data=data, x=\"agent\", shade=True)\n",
    "g.set_xlabel(\"agent\", size = 15)\n",
    "g.set_ylabel(\"Frequency\", size = 15)\n",
    "plt.title('Distribution of agent', size = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из анализа количества пропусков делаем следующие выводы:\n",
    "- Строки, содержащие пропуски в столбце \"country\", удаляем;\n",
    "- Для пропущенных значений в столбце \"agent\" сделаем импутацию медианой;\n",
    "- Столбец \"company\" удаляем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['company'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(subset=['country'], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator = MissingIndicator()\n",
    "mask_missing_values_only = indicator.fit_transform(data[['agent']])\n",
    "imp_num = SimpleImputer(strategy='median')\n",
    "data_num_imp = imp_num.fit_transform(data[['agent']])\n",
    "data['agent'] = data_num_imp\n",
    "filled_data = data_num_imp[mask_missing_values_only]\n",
    "print('agent', 'median', filled_data.size, filled_data[0], filled_data[filled_data.size-1], sep='; ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После применения импутации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Проверяем, что импутация не разрушила распределение\n",
    "g = sns.kdeplot(data=data, x=\"agent\", shade=True)\n",
    "g.set_xlabel(\"agent\", size = 15)\n",
    "g.set_ylabel(\"Frequency\", size = 15)\n",
    "plt.title('Distribution of agent', size = 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Проверяем категориальные признаки на уникальность\n",
    "col_obj = data.dtypes[data.dtypes==object].index.values.tolist()\n",
    "for i in enumerate(col_obj):\n",
    "    uniq_obj = data[i[1]].unique()\n",
    "    print(f'{i[0]+1}. {i[1]}: {uniq_obj} | КОЛ-ВО: {len(uniq_obj)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Копируем датасет и применяем label-encoding категориальных признаков для составления корреляционной матрицы \n",
    "# и последующего применения в модели Random Forest\n",
    "dataLE = data.copy()\n",
    "le = LabelEncoder()\n",
    "col_obj = dataLE.dtypes[dataLE.dtypes==object].index.values.tolist()\n",
    "for i in col_obj:\n",
    "    dataLE[i] = le.fit_transform(dataLE[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "g = sns.heatmap(dataLE.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оцениваем важность признаков для целевого\n",
    "(dataLE.corr()['is_canceled']*100).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По результатам корреляционного анализа удаляем столбцы, которые имеют меньшую значимость по отношению к целевому признаку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_data = (dataLE.corr()['is_canceled']*100).sort_values(ascending=False)\n",
    "del_col = del_data[(del_data < 10) & (del_data > -10) | (del_data.isnull())].index.values.tolist()\n",
    "data.drop(columns=del_col, inplace=True)\n",
    "dataLE.drop(columns=del_col, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполняем One-hot encoding для категориальных признаков и масштабирование числовых признаков для применения в SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выполняем one-hot encoding и масштабирование для применения в SVM\n",
    "col_num = data.dtypes[data.dtypes!=object].index.values.tolist()\n",
    "col_num.remove('is_canceled')\n",
    "se = StandardScaler()\n",
    "data[col_num] = se.fit_transform(data[col_num])\n",
    "data = pd.get_dummies(data, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.3\n",
    "RANDOM_STATE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataLE_X = dataLE.drop(columns='is_canceled')\n",
    "dataLE_y = dataLE['is_canceled']\n",
    "data_X = data.drop(columns='is_canceled')\n",
    "data_y = data['is_canceled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataLE_X_train, dataLE_X_test, dataLE_y_train, dataLE_y_test = train_test_split(dataLE_X, dataLE_y, \\\n",
    "                                                                                test_size = TEST_SIZE, \\\n",
    "                                                                                random_state= RANDOM_STATE)\n",
    "data_X_train, data_X_test, data_y_train, data_y_test = train_test_split(data_X, data_y, \\\n",
    "                                                                        test_size = TEST_SIZE, \\\n",
    "                                                                        random_state= RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(X_train, Y_train, X_test, Y_test, clf):\n",
    "    clf.fit(X_train, Y_train)\n",
    "    target = clf.predict(X_test)\n",
    "    print(f'Сбалансированная оценка: {balanced_accuracy_score(Y_test, target)}')\n",
    "    fig, ax = plt.subplots()\n",
    "    plot_roc_curve(clf, X_test, Y_test, ax=ax)\n",
    "    ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "            label='Chance', alpha=.8)\n",
    "    ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],\n",
    "           title=\"Receiver operating characteristic\")\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    print(f'Матрица ошибок:\\n {confusion_matrix(Y_test, target)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(data_X_train, data_y_train, data_X_test, data_y_test, DecisionTreeClassifier(random_state=RANDOM_STATE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print_metrics(dataLE_X_train, dataLE_y_train, dataLE_X_test, dataLE_y_test, RandomForestClassifier(random_state=RANDOM_STATE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данной работе для оценки моделей были использованы следующие метрики, подходящие для задачи бинарной классификации:\n",
    "- **balanced accuracy**, так как данная метрика хорошо интерпретируется и используется при несбалансированных классах\n",
    "- **ROC-кривая (AUC)**, так как позволяет по графику понять, насколько модель может минимизировать FP (False Positive), т.е. признавать отмененным заказ, который таковым не является, и минимизировать FN (False Negative), т.е. признавать бронированным заказ, который был отменен\n",
    "- **confusion matrix**, так как, хотя и метрикой в полной мере не является, позволяет увидеть общую картину по всем видам ошибок.\n",
    "\n",
    "По результатам оценивания можно сделать следующий вывод: модель Random Forest обладает немного большей предсказательной способностью, чем Support Vector Machine. Но при этом обе модели могут использоваться для предсказания, будет ли заказ по бронированию отменен, с минимальным количеством ошибок."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}